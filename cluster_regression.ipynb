{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fat</th>\n",
       "      <th>protein</th>\n",
       "      <th>carbohydrate</th>\n",
       "      <th>sugars</th>\n",
       "      <th>fiber</th>\n",
       "      <th>cholesterol</th>\n",
       "      <th>saturated_fats</th>\n",
       "      <th>calcium</th>\n",
       "      <th>iron</th>\n",
       "      <th>potassium</th>\n",
       "      <th>magnesium</th>\n",
       "      <th>vitamin_a</th>\n",
       "      <th>vitamin_c</th>\n",
       "      <th>vitamin_b12</th>\n",
       "      <th>vitamin_d</th>\n",
       "      <th>vitamin_e_alphatocopherol</th>\n",
       "      <th>water</th>\n",
       "      <th>omega_3s</th>\n",
       "      <th>omega_6s</th>\n",
       "      <th>pral_score</th>\n",
       "      <th>phosphorus</th>\n",
       "      <th>sodium</th>\n",
       "      <th>zinc</th>\n",
       "      <th>copper</th>\n",
       "      <th>selenium</th>\n",
       "      <th>thiamin_b1</th>\n",
       "      <th>riboflavin_b2</th>\n",
       "      <th>niacin_b3</th>\n",
       "      <th>vitamin_b6</th>\n",
       "      <th>folate_b9</th>\n",
       "      <th>folic_acid</th>\n",
       "      <th>food_folate</th>\n",
       "      <th>folate_dfe</th>\n",
       "      <th>choline</th>\n",
       "      <th>retinol</th>\n",
       "      <th>carotene_beta</th>\n",
       "      <th>carotene_alpha</th>\n",
       "      <th>lycopene</th>\n",
       "      <th>lutein_plus_zeaxanthin</th>\n",
       "      <th>vitamin_k</th>\n",
       "      <th>fatty_acids_total_monounsaturated</th>\n",
       "      <th>fatty_acids_total_polyunsaturated</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>caffeine</th>\n",
       "      <th>theobromine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5653</th>\n",
       "      <td>-0.679827</td>\n",
       "      <td>-1.036063</td>\n",
       "      <td>-0.300931</td>\n",
       "      <td>0.492466</td>\n",
       "      <td>-0.537367</td>\n",
       "      <td>-0.350203</td>\n",
       "      <td>-0.558501</td>\n",
       "      <td>-0.416059</td>\n",
       "      <td>-0.450038</td>\n",
       "      <td>-0.811608</td>\n",
       "      <td>-0.650832</td>\n",
       "      <td>-0.135566</td>\n",
       "      <td>-0.138123</td>\n",
       "      <td>0.409945</td>\n",
       "      <td>-0.148007</td>\n",
       "      <td>-0.296869</td>\n",
       "      <td>1.018601</td>\n",
       "      <td>-0.175639</td>\n",
       "      <td>-0.432520</td>\n",
       "      <td>-0.755126</td>\n",
       "      <td>-0.823591</td>\n",
       "      <td>-0.303481</td>\n",
       "      <td>-0.522053</td>\n",
       "      <td>-0.316597</td>\n",
       "      <td>-0.479409</td>\n",
       "      <td>-0.438419</td>\n",
       "      <td>-0.549280</td>\n",
       "      <td>-0.708121</td>\n",
       "      <td>1.770296</td>\n",
       "      <td>-0.376956</td>\n",
       "      <td>-0.176650</td>\n",
       "      <td>-0.482113</td>\n",
       "      <td>-0.312864</td>\n",
       "      <td>-0.574692</td>\n",
       "      <td>-0.092949</td>\n",
       "      <td>-0.237682</td>\n",
       "      <td>-0.140486</td>\n",
       "      <td>-0.15551</td>\n",
       "      <td>-0.202845</td>\n",
       "      <td>-0.232067</td>\n",
       "      <td>-0.572393</td>\n",
       "      <td>-0.452614</td>\n",
       "      <td>-0.079248</td>\n",
       "      <td>0.403413</td>\n",
       "      <td>-0.072008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9675</th>\n",
       "      <td>0.211305</td>\n",
       "      <td>0.401395</td>\n",
       "      <td>-0.153366</td>\n",
       "      <td>-0.206112</td>\n",
       "      <td>-0.018763</td>\n",
       "      <td>0.009872</td>\n",
       "      <td>0.321210</td>\n",
       "      <td>0.606675</td>\n",
       "      <td>-0.046611</td>\n",
       "      <td>-0.098200</td>\n",
       "      <td>-0.047258</td>\n",
       "      <td>-0.081624</td>\n",
       "      <td>-0.106019</td>\n",
       "      <td>0.030653</td>\n",
       "      <td>-0.085440</td>\n",
       "      <td>-0.159159</td>\n",
       "      <td>-0.136939</td>\n",
       "      <td>-0.172645</td>\n",
       "      <td>-0.023525</td>\n",
       "      <td>0.021437</td>\n",
       "      <td>0.243680</td>\n",
       "      <td>0.257249</td>\n",
       "      <td>0.384729</td>\n",
       "      <td>-0.128166</td>\n",
       "      <td>0.158436</td>\n",
       "      <td>-0.069342</td>\n",
       "      <td>-0.069183</td>\n",
       "      <td>0.074870</td>\n",
       "      <td>-0.087652</td>\n",
       "      <td>-0.092188</td>\n",
       "      <td>-0.125722</td>\n",
       "      <td>0.052281</td>\n",
       "      <td>-0.097005</td>\n",
       "      <td>0.146798</td>\n",
       "      <td>-0.049777</td>\n",
       "      <td>-0.169886</td>\n",
       "      <td>-0.105463</td>\n",
       "      <td>0.56036</td>\n",
       "      <td>-0.168559</td>\n",
       "      <td>-0.115501</td>\n",
       "      <td>0.125090</td>\n",
       "      <td>-0.030031</td>\n",
       "      <td>-0.079248</td>\n",
       "      <td>-0.030786</td>\n",
       "      <td>-0.072008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8162</th>\n",
       "      <td>0.469108</td>\n",
       "      <td>-0.850584</td>\n",
       "      <td>-0.046867</td>\n",
       "      <td>0.789298</td>\n",
       "      <td>-0.293318</td>\n",
       "      <td>0.081888</td>\n",
       "      <td>1.337468</td>\n",
       "      <td>-0.214037</td>\n",
       "      <td>-0.411291</td>\n",
       "      <td>-0.389454</td>\n",
       "      <td>-0.449640</td>\n",
       "      <td>0.114270</td>\n",
       "      <td>0.049436</td>\n",
       "      <td>-0.239124</td>\n",
       "      <td>0.070978</td>\n",
       "      <td>-0.129650</td>\n",
       "      <td>0.156620</td>\n",
       "      <td>-0.163661</td>\n",
       "      <td>-0.278106</td>\n",
       "      <td>-0.591666</td>\n",
       "      <td>-0.626832</td>\n",
       "      <td>-0.368234</td>\n",
       "      <td>-0.469864</td>\n",
       "      <td>-0.244431</td>\n",
       "      <td>-0.416367</td>\n",
       "      <td>-0.386475</td>\n",
       "      <td>-0.269224</td>\n",
       "      <td>-0.646132</td>\n",
       "      <td>-0.422313</td>\n",
       "      <td>-0.285423</td>\n",
       "      <td>-0.176650</td>\n",
       "      <td>-0.281715</td>\n",
       "      <td>-0.250196</td>\n",
       "      <td>-0.382806</td>\n",
       "      <td>0.154568</td>\n",
       "      <td>-0.199594</td>\n",
       "      <td>-0.131730</td>\n",
       "      <td>-0.15551</td>\n",
       "      <td>-0.193141</td>\n",
       "      <td>-0.207266</td>\n",
       "      <td>0.085069</td>\n",
       "      <td>-0.284011</td>\n",
       "      <td>-0.079248</td>\n",
       "      <td>-0.030786</td>\n",
       "      <td>-0.072008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7994</th>\n",
       "      <td>-0.425750</td>\n",
       "      <td>-0.883558</td>\n",
       "      <td>-0.472413</td>\n",
       "      <td>0.168339</td>\n",
       "      <td>-0.537367</td>\n",
       "      <td>-0.350203</td>\n",
       "      <td>-0.281727</td>\n",
       "      <td>-0.119340</td>\n",
       "      <td>-0.219834</td>\n",
       "      <td>-0.575987</td>\n",
       "      <td>-0.516704</td>\n",
       "      <td>-0.048975</td>\n",
       "      <td>-0.024912</td>\n",
       "      <td>-0.199058</td>\n",
       "      <td>0.164829</td>\n",
       "      <td>-0.103419</td>\n",
       "      <td>0.968116</td>\n",
       "      <td>-0.166655</td>\n",
       "      <td>-0.279986</td>\n",
       "      <td>-0.673139</td>\n",
       "      <td>-0.674531</td>\n",
       "      <td>-0.390277</td>\n",
       "      <td>-0.342654</td>\n",
       "      <td>-0.192312</td>\n",
       "      <td>-0.405241</td>\n",
       "      <td>-0.255248</td>\n",
       "      <td>-0.280654</td>\n",
       "      <td>-0.529522</td>\n",
       "      <td>-0.488668</td>\n",
       "      <td>-0.275253</td>\n",
       "      <td>-0.049330</td>\n",
       "      <td>-0.482113</td>\n",
       "      <td>-0.194490</td>\n",
       "      <td>-0.265756</td>\n",
       "      <td>-0.005167</td>\n",
       "      <td>-0.237682</td>\n",
       "      <td>-0.140486</td>\n",
       "      <td>-0.15551</td>\n",
       "      <td>-0.202845</td>\n",
       "      <td>-0.165103</td>\n",
       "      <td>-0.362114</td>\n",
       "      <td>-0.294534</td>\n",
       "      <td>-0.079248</td>\n",
       "      <td>-0.030786</td>\n",
       "      <td>-0.072008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10728</th>\n",
       "      <td>0.223227</td>\n",
       "      <td>-0.781545</td>\n",
       "      <td>0.905760</td>\n",
       "      <td>1.042629</td>\n",
       "      <td>0.072756</td>\n",
       "      <td>-0.350203</td>\n",
       "      <td>0.023131</td>\n",
       "      <td>-0.365553</td>\n",
       "      <td>-0.190204</td>\n",
       "      <td>-0.582532</td>\n",
       "      <td>-0.471995</td>\n",
       "      <td>-0.135566</td>\n",
       "      <td>-0.112777</td>\n",
       "      <td>-0.257822</td>\n",
       "      <td>-0.148007</td>\n",
       "      <td>-0.037843</td>\n",
       "      <td>-0.548297</td>\n",
       "      <td>0.051954</td>\n",
       "      <td>0.435688</td>\n",
       "      <td>-0.687147</td>\n",
       "      <td>-0.644719</td>\n",
       "      <td>-0.095446</td>\n",
       "      <td>-0.456817</td>\n",
       "      <td>-0.182289</td>\n",
       "      <td>-0.193862</td>\n",
       "      <td>-0.036535</td>\n",
       "      <td>-0.226358</td>\n",
       "      <td>-0.390047</td>\n",
       "      <td>-0.572333</td>\n",
       "      <td>-0.071847</td>\n",
       "      <td>0.128918</td>\n",
       "      <td>-0.348515</td>\n",
       "      <td>0.014406</td>\n",
       "      <td>-0.488343</td>\n",
       "      <td>-0.092949</td>\n",
       "      <td>-0.233873</td>\n",
       "      <td>-0.140486</td>\n",
       "      <td>-0.15551</td>\n",
       "      <td>-0.189907</td>\n",
       "      <td>-0.129141</td>\n",
       "      <td>0.264315</td>\n",
       "      <td>0.375094</td>\n",
       "      <td>-0.079248</td>\n",
       "      <td>-0.030786</td>\n",
       "      <td>-0.072008</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            fat   protein  carbohydrate    sugars     fiber  cholesterol  \\\n",
       "5653  -0.679827 -1.036063     -0.300931  0.492466 -0.537367    -0.350203   \n",
       "9675   0.211305  0.401395     -0.153366 -0.206112 -0.018763     0.009872   \n",
       "8162   0.469108 -0.850584     -0.046867  0.789298 -0.293318     0.081888   \n",
       "7994  -0.425750 -0.883558     -0.472413  0.168339 -0.537367    -0.350203   \n",
       "10728  0.223227 -0.781545      0.905760  1.042629  0.072756    -0.350203   \n",
       "\n",
       "       saturated_fats   calcium      iron  potassium  magnesium  vitamin_a  \\\n",
       "5653        -0.558501 -0.416059 -0.450038  -0.811608  -0.650832  -0.135566   \n",
       "9675         0.321210  0.606675 -0.046611  -0.098200  -0.047258  -0.081624   \n",
       "8162         1.337468 -0.214037 -0.411291  -0.389454  -0.449640   0.114270   \n",
       "7994        -0.281727 -0.119340 -0.219834  -0.575987  -0.516704  -0.048975   \n",
       "10728        0.023131 -0.365553 -0.190204  -0.582532  -0.471995  -0.135566   \n",
       "\n",
       "       vitamin_c  vitamin_b12  vitamin_d  vitamin_e_alphatocopherol     water  \\\n",
       "5653   -0.138123     0.409945  -0.148007                  -0.296869  1.018601   \n",
       "9675   -0.106019     0.030653  -0.085440                  -0.159159 -0.136939   \n",
       "8162    0.049436    -0.239124   0.070978                  -0.129650  0.156620   \n",
       "7994   -0.024912    -0.199058   0.164829                  -0.103419  0.968116   \n",
       "10728  -0.112777    -0.257822  -0.148007                  -0.037843 -0.548297   \n",
       "\n",
       "       omega_3s  omega_6s  pral_score  phosphorus    sodium      zinc  \\\n",
       "5653  -0.175639 -0.432520   -0.755126   -0.823591 -0.303481 -0.522053   \n",
       "9675  -0.172645 -0.023525    0.021437    0.243680  0.257249  0.384729   \n",
       "8162  -0.163661 -0.278106   -0.591666   -0.626832 -0.368234 -0.469864   \n",
       "7994  -0.166655 -0.279986   -0.673139   -0.674531 -0.390277 -0.342654   \n",
       "10728  0.051954  0.435688   -0.687147   -0.644719 -0.095446 -0.456817   \n",
       "\n",
       "         copper  selenium  thiamin_b1  riboflavin_b2  niacin_b3  vitamin_b6  \\\n",
       "5653  -0.316597 -0.479409   -0.438419      -0.549280  -0.708121    1.770296   \n",
       "9675  -0.128166  0.158436   -0.069342      -0.069183   0.074870   -0.087652   \n",
       "8162  -0.244431 -0.416367   -0.386475      -0.269224  -0.646132   -0.422313   \n",
       "7994  -0.192312 -0.405241   -0.255248      -0.280654  -0.529522   -0.488668   \n",
       "10728 -0.182289 -0.193862   -0.036535      -0.226358  -0.390047   -0.572333   \n",
       "\n",
       "       folate_b9  folic_acid  food_folate  folate_dfe   choline   retinol  \\\n",
       "5653   -0.376956   -0.176650    -0.482113   -0.312864 -0.574692 -0.092949   \n",
       "9675   -0.092188   -0.125722     0.052281   -0.097005  0.146798 -0.049777   \n",
       "8162   -0.285423   -0.176650    -0.281715   -0.250196 -0.382806  0.154568   \n",
       "7994   -0.275253   -0.049330    -0.482113   -0.194490 -0.265756 -0.005167   \n",
       "10728  -0.071847    0.128918    -0.348515    0.014406 -0.488343 -0.092949   \n",
       "\n",
       "       carotene_beta  carotene_alpha  lycopene  lutein_plus_zeaxanthin  \\\n",
       "5653       -0.237682       -0.140486  -0.15551               -0.202845   \n",
       "9675       -0.169886       -0.105463   0.56036               -0.168559   \n",
       "8162       -0.199594       -0.131730  -0.15551               -0.193141   \n",
       "7994       -0.237682       -0.140486  -0.15551               -0.202845   \n",
       "10728      -0.233873       -0.140486  -0.15551               -0.189907   \n",
       "\n",
       "       vitamin_k  fatty_acids_total_monounsaturated  \\\n",
       "5653   -0.232067                          -0.572393   \n",
       "9675   -0.115501                           0.125090   \n",
       "8162   -0.207266                           0.085069   \n",
       "7994   -0.165103                          -0.362114   \n",
       "10728  -0.129141                           0.264315   \n",
       "\n",
       "       fatty_acids_total_polyunsaturated   alcohol  caffeine  theobromine  \n",
       "5653                           -0.452614 -0.079248  0.403413    -0.072008  \n",
       "9675                           -0.030031 -0.079248 -0.030786    -0.072008  \n",
       "8162                           -0.284011 -0.079248 -0.030786    -0.072008  \n",
       "7994                           -0.294534 -0.079248 -0.030786    -0.072008  \n",
       "10728                           0.375094 -0.079248 -0.030786    -0.072008  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans, DBSCAN\n",
    "from prepare import Prepare\n",
    "from split_get_scale import SplitGetScale\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression, LassoCV, RidgeCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "nutrition_facts = Prepare().get_food_prep()\n",
    "\n",
    "sgs = SplitGetScale()\n",
    "train, validate, test = sgs.split(nutrition_facts)\n",
    "(X_train, y_train), (X_validate, y_validate), (X_test, y_test) = sgs.get_Xy(train, validate, test, target_col=\"calories\", cols_drop=[\"food_group\", \"calories\"])\n",
    "\n",
    "X_train_scaled, X_validate_scaled, X_test_scaled = sgs.scale(X_train, X_validate, X_test)\n",
    "\n",
    "X_train_scaled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\"vitamin_a\", \"vitamin_c\", \"vitamin_b12\", \"vitamin_d\", \"vitamin_e_alphatocopherol\", \"thiamin_b1\", \"riboflavin_b2\", \"niacin_b3\", \"vitamin_b6\", \"folate_b9\", \"vitamin_k\"]\n",
    "\n",
    "clusters_train = X_train_scaled[features]\n",
    "clusters_validate = X_validate_scaled[features]\n",
    "clusters_test = X_test_scaled[features]\n",
    "\n",
    "# creating the object\n",
    "kmeans = KMeans(n_clusters=8, max_iter=500)\n",
    "\n",
    "# fitting the object\n",
    "kmeans.fit(clusters_train)\n",
    "\n",
    "#predicting using the kmeans object\n",
    "y_kmeans_train = kmeans.predict(clusters_train)\n",
    "X_train_scaled['feat_clusters'] = y_kmeans_train\n",
    "\n",
    "#predicting using the kmeans object\n",
    "y_kmeans_validate = kmeans.predict(clusters_validate)\n",
    "X_validate_scaled['feat_clusters'] = y_kmeans_validate\n",
    "\n",
    "#predicting using the kmeans object\n",
    "y_kmeans_test = kmeans.predict(clusters_test)\n",
    "X_test_scaled['feat_clusters'] = y_kmeans_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN\\X_train_scaled Shape: (9544, 46)\n",
      "y_train Shape: (9544,)\n",
      "VALIDATE\\X_validate_scaled Shape: (2386, 46)\n",
      "y_validate Shape: (2386,)\n",
      "TEST\\X_test_scaled Shape: (2106, 46)\n",
      "y_test Shape: (2106,)\n"
     ]
    }
   ],
   "source": [
    "print(f\"TRAIN\\X_train_scaled Shape: {X_train_scaled.shape}\")\n",
    "print(f\"y_train Shape: {y_train.shape}\")\n",
    "print(f\"VALIDATE\\X_validate_scaled Shape: {X_validate_scaled.shape}\")\n",
    "print(f\"y_validate Shape: {y_validate.shape}\")\n",
    "print(f\"TEST\\X_test_scaled Shape: {X_test_scaled.shape}\")\n",
    "print(f\"y_test Shape: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "149.2582021605062"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "act_pred_error = pd.DataFrame({\"actual\": y_train})\n",
    "act_pred_error[\"baseline_prediction\"] = y_train.mean()\n",
    "baseline_rmse = mean_squared_error(act_pred_error[\"actual\"], act_pred_error[\"baseline_prediction\"], squared=False)\n",
    "baseline_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search(X, y, model, params_dic):\n",
    "    grid = RandomizedSearchCV(model, params_dic, n_jobs=-1)\n",
    "    return grid.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random forest regressor: RandomForestRegressor(max_depth=25, n_estimators=10, n_jobs=-1,\n",
      "                      random_state=123, warm_start=True)\n",
      "random forest regressor: {'warm_start': True, 'n_estimators': 10, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_depth': 25, 'bootstrap': True}\n"
     ]
    }
   ],
   "source": [
    "rfr_grid = {\"n_estimators\": [10, 25, 50, 75, 100] , \"max_depth\": [None, 10, 25, 50] , \"min_samples_split\": [2, 4, 6, 8, 10], \"min_samples_leaf\": [1, 2.5, 5,], \"bootstrap\": [True, False], \"warm_start\": [False, True]}\n",
    "rfr = grid_search(X_train_scaled, y_train, RandomForestRegressor(random_state=123, n_jobs=-1), rfr_grid)\n",
    "\n",
    "print(f\"random forest regressor: {rfr.best_estimator_}\")\n",
    "print(f\"random forest regressor: {rfr.best_params_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso = LassoCV(random_state=123).fit(X_train_scaled, y_train)\n",
    "ridge = RidgeCV().fit(X_train_scaled, y_train)\n",
    "rfr = RandomForestRegressor(n_estimators=10, max_depth=25, min_samples_split=2, min_samples_leaf=1, bootstrap=True, warm_start=True, random_state=123, n_jobs=-1).fit(X_train_scaled, y_train)\n",
    "lr = LinearRegression().fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN\n",
      "lasso train rmse: 7.407998823002653\n",
      "ridge train rmse: 7.10763970624999\n",
      "rfr train rmse: 4.268055366061249\n",
      "lr train rmse: 7.107435935804069\n",
      "VALIDATE\n",
      "lasso validation rmse: 8.745662599770194\n",
      "ridge validation rmse: 7.961317627625173\n",
      "rfr validation rmse: 10.686753744206765\n",
      "lr validation rmse: 7.960004839921713\n"
     ]
    }
   ],
   "source": [
    "lass_pred_train = lasso.predict(X_train_scaled)\n",
    "ridge_pred_train = ridge.predict(X_train_scaled)\n",
    "rfr_pred_train = rfr.predict(X_train_scaled)\n",
    "lr_pred_train = lr.predict(X_train_scaled)\n",
    "\n",
    "lass_pred_val = lasso.predict(X_validate_scaled)\n",
    "ridge_pred_val = ridge.predict(X_validate_scaled)\n",
    "rfr_pred_val = rfr.predict(X_validate_scaled)\n",
    "lr_pred_val = lr.predict(X_validate_scaled)\n",
    "\n",
    "print(f\"TRAIN\\nlasso train rmse: {mean_squared_error(y_train, lass_pred_train, squared=False)}\\nridge train rmse: {mean_squared_error(y_train, ridge_pred_train, squared=False)}\\nrfr train rmse: {mean_squared_error(y_train, rfr_pred_train, squared=False)}\\nlr train rmse: { mean_squared_error(y_train, lr_pred_train, squared=False)}\")\n",
    "\n",
    "print(f\"VALIDATE\\nlasso validation rmse: {mean_squared_error(y_validate, lass_pred_val, squared=False)}\\nridge validation rmse: {mean_squared_error(y_validate, ridge_pred_val, squared=False)}\\nrfr validation rmse: {mean_squared_error(y_validate, rfr_pred_val, squared=False)}\\nlr validation rmse: { mean_squared_error(y_validate, lr_pred_val, squared=False)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression is best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr test rmse: 11.250274985444475\n"
     ]
    }
   ],
   "source": [
    "lr_pred_test = lr.predict(X_test_scaled)\n",
    "print(f\"lr test rmse: {mean_squared_error(y_test, lr_pred_test, squared=False)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3d597f4c481aa0f25dceb95d2a0067e73c0966dcbd003d741d821a7208527ecf"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
